> /tmp/ipykernel_150131/3323629273.py(91)compute_loss()
     89         self.log(log)
     90         import pdb; pdb.set_trace()
---> 91         return (loss,  logits) #if return_outputs else loss#lossloss,
     92
     93
torch.Size([1, 4, 1022, 32000])
tensor([[[[-115.6250,  -52.8438,   53.7500,  ...,  -90.3125, -112.7500,
            -69.5000],
          [-118.5000,  -49.3438,   71.9375,  ..., -106.8750, -118.7500,
            -66.8750],
          [ -93.6875,  -47.9688,   49.1875,  ...,  -98.9375,  -80.1250,
            -62.2188],
          ...,
          [-141.2500,  -82.6250,   61.5312,  ..., -120.0000, -140.7500,
            -91.1250],
          [-136.1250,  -77.5000,   61.4375,  ..., -112.3125, -134.0000,
            -79.1875],
          [-130.2500,  -72.5625,   57.6250,  ..., -104.3125, -125.9375,
            -71.8750]],
         [[-115.6250,  -52.8438,   53.7500,  ...,  -90.3125, -112.7500,
            -69.5000],
          [-118.5000,  -49.3438,   71.9375,  ..., -106.8750, -118.7500,
            -66.8750],
          [ -93.6875,  -47.9688,   49.1875,  ...,  -98.9375,  -80.1250,
            -62.2188],
          ...,
          [ -75.2500,  -43.1875,   41.0000,  ...,  -97.0000,  -83.7500,
            -39.0000],
          [ -68.0625,  -39.6250,   37.1562,  ...,  -95.0000,  -78.7500,
            -36.3750],
          [ -68.2500,  -41.8125,   36.0625,  ...,  -97.1250,  -75.2500,
            -36.2812]],
         [[-115.6250,  -52.8438,   53.7500,  ...,  -90.3125, -112.7500,
            -69.5000],
          [-118.5000,  -49.3438,   71.9375,  ..., -106.8750, -118.7500,
            -66.8750],
          [ -93.6875,  -47.9688,   49.1875,  ...,  -98.9375,  -80.1250,
            -62.2188],
          ...,
          [-156.6250,  -69.3125,   67.4375,  ..., -133.0000, -133.7500,
           -101.8125],
          [-122.5000,  -81.2500,   40.0625,  ..., -106.5625,  -99.8750,
            -66.4375],
          [ -91.8750,  -28.2188,    6.1484,  ..., -108.1875,  -80.5000,
            -40.5312]],
         [[-115.6250,  -52.8438,   53.7500,  ...,  -90.3125, -112.7500,
            -69.5000],
          [-118.5000,  -49.3438,   71.9375,  ..., -106.8750, -118.7500,
            -66.8750],
          [ -93.6875,  -47.9688,   49.1875,  ...,  -98.9375,  -80.1250,
            -62.2188],
          ...,
          [ -65.0625,  -34.9062,    6.5703,  ...,  -63.2188,  -50.5625,
            -39.8750],
          [ -92.5625,  -74.8750,   21.4219,  ..., -106.1250,  -67.3125,
            -55.5000],
          [ -94.3125,  -75.2500,   24.3125,  ..., -102.4375,  -84.0000,
            -36.3125]]]], device='cuda:0')
> /tmp/ipykernel_150131/3323629273.py(91)compute_loss()
     89         self.log(log)
     90         import pdb; pdb.set_trace()
---> 91         return (loss,  logits) #if return_outputs else loss#lossloss,
     92
     93
> /tmp/ipykernel_150131/3323629273.py(91)compute_loss()
     89         self.log(log)
     90         import pdb; pdb.set_trace()
---> 91         return (loss,  logits) #if return_outputs else loss#lossloss,
     92
     93
> /tmp/ipykernel_150131/3323629273.py(91)compute_loss()
     89         self.log(log)
     90         import pdb; pdb.set_trace()
---> 91         return (loss,  logits) #if return_outputs else loss#lossloss,
     92
     93
> /tmp/ipykernel_150131/775524108.py(10)compute_metrics()
      8         import pdb; pdb.set_trace()
      9         #print(labels.shape)
---> 10         medusa_logits = logits[0,:, : ].contiguous()
     11
     12         medusa_labels = labels[...,  1:].contiguous()
Loading data...
Formatting inputs...Skip in lazy mode
Formatting inputs...Skip in lazy mode
> /tmp/ipykernel_150131/3323629273.py(91)compute_loss()
     89         self.log(log)
     90         import pdb; pdb.set_trace()
---> 91         return (loss,  logits) #if return_outputs else loss#lossloss,
     92
     93
> /tmp/ipykernel_150131/3323629273.py(91)compute_loss()
     89         self.log(log)
     90         import pdb; pdb.set_trace()
---> 91         return (loss,  logits) #if return_outputs else loss#lossloss,
     92
     93
> /tmp/ipykernel_150131/3323629273.py(91)compute_loss()
     89         self.log(log)
     90         import pdb; pdb.set_trace()
---> 91         return (loss,  logits) #if return_outputs else loss#lossloss,
     92
     93
> /tmp/ipykernel_150131/3323629273.py(91)compute_loss()
     89         self.log(log)
     90         import pdb; pdb.set_trace()
---> 91         return (loss,  logits) #if return_outputs else loss#lossloss,
     92
     93
> /tmp/ipykernel_150131/775524108.py(10)compute_metrics()
      8         import pdb; pdb.set_trace()
      9         #print(labels.shape)
---> 10         medusa_logits = logits[0,:, : ].contiguous()
     11
     12         medusa_labels = labels[...,  1:].contiguous()
*** NameError: name 'logtis' is not defined
<transformers.trainer_utils.EvalPrediction object at 0x7f24f07da8f0>
(array([], shape=(0, 4, 1022, 32000), dtype=float32), array([[ -100,  -100,  -100, ...,  -100,  -100,  -100],
       [ -100,  -100,  -100, ...,  -100,  -100,  -100],
       [ -100,  -100,  -100, ...,   893, 29874,   313],
       ...,
       [ -100,  -100,  -100, ..., 29879,  1950,   393],
       [ -100,  -100,  -100, ...,  -100,  -100,  -100],
       [ -100,  -100,  -100, ...,   890,    13,    13]]))
--KeyboardInterrupt--
KeyboardInterrupt: Interrupted by user
KeyboardInterrupt
> /tmp/ipykernel_150131/3323629273.py(91)compute_loss()
     89         self.log(log)
     90         import pdb; pdb.set_trace()
---> 91         return (loss,  logits) #if return_outputs else loss#lossloss,
     92
     93
--KeyboardInterrupt--
KeyboardInterrupt: Interrupted by user
KeyboardInterrupt
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at ../../../../../model/TinyLlama-1.1B-Chat-v0.6 and are newly initialized: ['model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
path ../../../../../model/TinyLlama-1.1B-Chat-v0.6
path:  ../../../../../model/TinyLlama-1.1B-Chat-v0.6
Loading data...
Formatting inputs...Skip in lazy mode
Formatting inputs...Skip in lazy mode
> /tmp/ipykernel_150131/775524108.py(10)compute_metrics()
      8         import pdb; pdb.set_trace()
      9         #print(labels.shape)
---> 10         medusa_logits = logits[0,:, : ].contiguous()
     11
     12         medusa_labels = labels[...,  1:].contiguous()
--KeyboardInterrupt--
KeyboardInterrupt: Interrupted by user
KeyboardInterrupt
path ../../../../../model/TinyLlama-1.1B-Chat-v0.6
path:  ../../../../../model/TinyLlama-1.1B-Chat-v0.6
Loading data...
Formatting inputs...Skip in lazy mode
Formatting inputs...Skip in lazy mode
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at ../../../../../model/TinyLlama-1.1B-Chat-v0.6 and are newly initialized: ['model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at ../../../../../model/TinyLlama-1.1B-Chat-v0.6 and are newly initialized: ['model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
path ../../../../../model/TinyLlama-1.1B-Chat-v0.6
path:  ../../../../../model/TinyLlama-1.1B-Chat-v0.6
Loading data...
Formatting inputs...Skip in lazy mode
Formatting inputs...Skip in lazy mode
> /tmp/ipykernel_150131/2223075977.py(92)compute_loss()
     90         import pdb; pdb.set_trace()
     91        # return (loss,  logits) if return_outputs else loss+logits1[-1]#lossloss,
---> 92         return loss+logits1[-1]
     93
     94
tensor(58.2364, device='cuda:0', grad_fn=<AddBackward0>)
tensor([[[[-115.6250,  -52.8438,   53.7500,  ...,  -90.3125, -112.7500,
            -69.5000],
          [-118.5000,  -49.3438,   71.9375,  ..., -106.8750, -118.7500,
            -66.8750],
          [ -93.6875,  -47.9688,   49.1875,  ...,  -98.9375,  -80.1250,
            -62.2188],
          ...,
          [ -75.2500,  -43.1875,   41.0000,  ...,  -97.0000,  -83.7500,
            -39.0000],
          [ -68.0625,  -39.6250,   37.1562,  ...,  -95.0000,  -78.7500,
            -36.3750],
          [ -68.2500,  -41.8125,   36.0625,  ...,  -97.1250,  -75.2500,
            -36.2812]],
         [[-115.6250,  -52.8438,   53.7500,  ...,  -90.3125, -112.7500,
            -69.5000],
          [-118.5000,  -49.3438,   71.9375,  ..., -106.8750, -118.7500,
            -66.8750],
          [ -93.6875,  -47.9688,   49.1875,  ...,  -98.9375,  -80.1250,
            -62.2188],
          ...,
          [-156.6250,  -69.3125,   67.4375,  ..., -133.0000, -133.7500,
           -101.8125],
          [-122.5000,  -81.2500,   40.0625,  ..., -106.5625,  -99.8750,
            -66.4375],
          [ -91.8750,  -28.2188,    6.1484,  ..., -108.1875,  -80.5000,
            -40.5312]],
         [[-115.6250,  -52.8438,   53.7500,  ...,  -90.3125, -112.7500,
            -69.5000],
          [-118.5000,  -49.3438,   71.9375,  ..., -106.8750, -118.7500,
            -66.8750],
          [ -93.6875,  -47.9688,   49.1875,  ...,  -98.9375,  -80.1250,
            -62.2188],
          ...,
          [ -93.6250,  -47.6250,   83.5000,  ...,  -96.1250,  -87.5625,
            -74.5000],
          [ -63.9688,  -27.3125,   60.9062,  ...,  -99.6875,  -67.8125,
            -58.5312],
          [ -60.8125,  -35.4688,   23.9688,  ...,  -89.0000,  -65.2500,
            -50.8438]],
         [[-115.6250,  -52.8438,   53.7500,  ...,  -90.3125, -112.7500,
            -69.5000],
          [-118.5000,  -49.3438,   71.9375,  ..., -106.8750, -118.7500,
            -66.8750],
          [ -93.6875,  -47.9688,   49.1875,  ...,  -98.9375,  -80.1250,
            -62.2188],
          ...,
          [ -95.4375,  -39.3438,   79.6875,  ..., -103.2500,  -84.4375,
            -46.3125],
          [-121.4375,  -48.3438,   98.4375,  ..., -119.3125,  -99.9375,
            -81.2500],
          [ -54.9062,  -18.3438,   43.5625,  ...,  -77.2500,  -40.0312,
            -70.8125]]]], device='cuda:0', grad_fn=<SelectBackward0>)
tensor([[[[[-115.6250,  -52.8438,   53.7500,  ...,  -90.3125, -112.7500,
             -69.5000],
           [-118.5000,  -49.3438,   71.9375,  ..., -106.8750, -118.7500,
             -66.8750],
           [ -93.6875,  -47.9688,   49.1875,  ...,  -98.9375,  -80.1250,
             -62.2188],
           ...,
           [ -75.2500,  -43.1875,   41.0000,  ...,  -97.0000,  -83.7500,
             -39.0000],
           [ -68.0625,  -39.6250,   37.1562,  ...,  -95.0000,  -78.7500,
             -36.3750],
           [ -68.2500,  -41.8125,   36.0625,  ...,  -97.1250,  -75.2500,
             -36.2812]],
          [[-115.6250,  -52.8438,   53.7500,  ...,  -90.3125, -112.7500,
             -69.5000],
           [-118.5000,  -49.3438,   71.9375,  ..., -106.8750, -118.7500,
             -66.8750],
           [ -93.6875,  -47.9688,   49.1875,  ...,  -98.9375,  -80.1250,
             -62.2188],
           ...,
           [-156.6250,  -69.3125,   67.4375,  ..., -133.0000, -133.7500,
            -101.8125],
           [-122.5000,  -81.2500,   40.0625,  ..., -106.5625,  -99.8750,
             -66.4375],
           [ -91.8750,  -28.2188,    6.1484,  ..., -108.1875,  -80.5000,
             -40.5312]],
          [[-115.6250,  -52.8438,   53.7500,  ...,  -90.3125, -112.7500,
             -69.5000],
           [-118.5000,  -49.3438,   71.9375,  ..., -106.8750, -118.7500,
             -66.8750],
           [ -93.6875,  -47.9688,   49.1875,  ...,  -98.9375,  -80.1250,
             -62.2188],
           ...,
           [ -93.6250,  -47.6250,   83.5000,  ...,  -96.1250,  -87.5625,
             -74.5000],
           [ -63.9688,  -27.3125,   60.9062,  ...,  -99.6875,  -67.8125,
             -58.5312],
           [ -60.8125,  -35.4688,   23.9688,  ...,  -89.0000,  -65.2500,
             -50.8438]],
          [[-115.6250,  -52.8438,   53.7500,  ...,  -90.3125, -112.7500,
             -69.5000],
           [-118.5000,  -49.3438,   71.9375,  ..., -106.8750, -118.7500,
             -66.8750],
           [ -93.6875,  -47.9688,   49.1875,  ...,  -98.9375,  -80.1250,
             -62.2188],
           ...,
           [ -95.4375,  -39.3438,   79.6875,  ..., -103.2500,  -84.4375,
             -46.3125],
           [-121.4375,  -48.3438,   98.4375,  ..., -119.3125,  -99.9375,
             -81.2500],
           [ -54.9062,  -18.3438,   43.5625,  ...,  -77.2500,  -40.0312,
             -70.8125]]]]], device='cuda:0', grad_fn=<ToCopyBackward0>)
torch.Size([1, 4, 1022, 32000])
--KeyboardInterrupt--
KeyboardInterrupt: Interrupted by user